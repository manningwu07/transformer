Launch with python
python3 -m venv .venv
source .venv/bin/activate
pip3 install -r requirements.text

Run the python files in dataExtraction folder

python3 dataExtraction/getData.py
python3 dataExtraction/tokenizer.py
python3 dataExtraction/makeDataset.py
To get vocab

Next, train on python
python3 train.py --train data/test/wiki_train_ids --test data/test/wiki_eval_ids --val data/test/wiki_val_ids --vocab data/test/vocab.json


Open up connection between the 2:
uvicorn server:app --reload --port 8000
python3 CLI.py

Use --resume & --resumePath path to continue training process
use --eval & --eval path to see effectiveness of model

Check if data is good:
python3 -c "import numpy as np; a=np.memmap('data/test/wiki_train_ids-000.bin',dtype=np.int32,mode='r'); import json; t=json.load(open('data/test/vocab.json')); print('pad id=', t['TokenToID']['<pad>']); print(np.unique(a[:100000], return_counts=True))"
