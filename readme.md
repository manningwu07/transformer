## This is the pytorch transfer of the transformer project

- Using the code here, I created a ~100M param model that rivals ChatGPT-2 (mini) on just the wiki
    - This thing is built from scratch and I've spent way too much compute on this project (m4 pro---20 battery cycles)
- In essence, this thing is meant for testing large scale stuff
- The go-only branch was to learn the inner workings of a transfomrer, as well as how to scale to ~10-100m params

### Please check out the go-only branch for better description